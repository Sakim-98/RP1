{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import glob,os\n",
    "from tika import parser\n",
    "from Bio import Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = 'User email address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = Entrez.esearch(db = 'pubmed', term = \"Mass spectrometry AND lipid AND brain\")\n",
    "record = Entrez.read(handle)\n",
    "count = int(record['Count'])\n",
    "handle = Entrez.esearch(db = 'pubmed', term = \"Mass spectrometry AND lipid AND brain\", retmax=count)\n",
    "record = Entrez.read(handle)\n",
    "handle.close() #Search on Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('file_1.txt', 'w') as file:\n",
    "    for i in record['IdList']:\n",
    "        print(i + ',', end=\"\", file=file) #Save the PMIDs in a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the file is downloaded containing the PMIDs, use the fetch_pdfs.py script to download the journal articles. \n",
    "\n",
    "The script can be found in the following link,\n",
    "\n",
    "https://github.com/billgreenwald/Pubmed-Batch-Download\n",
    "\n",
    "An example of usage, \n",
    "\n",
    "Python3 fetch_pdfs.py -pmids 1234,6789 \n",
    "\n",
    "Once the files are downloaded, continue with the next step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "path = r'D:\\fetched_pdfs' #the path where the pdf files are\n",
    "    \n",
    "os.chdir(path)\n",
    "pdfs = []\n",
    "for file in glob.glob(\"*.pdf\"):\n",
    "    pdfs.append(file) #get the names of all pdf files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFullPdf(f): \n",
    "    \n",
    "    '''Check for broken PDF files'''\n",
    "    \n",
    "    end_content = ''\n",
    "    start_content = ''\n",
    "    size = os.path.getsize(f)\n",
    "    if size < 1024: return False \n",
    "    with open(f, 'rb') as fin: \n",
    "        #start content \n",
    "        fin.seek(0, 0)\n",
    "        start_content = fin.read(1024)\n",
    "        start_content = start_content.decode(\"ascii\", 'ignore' )\n",
    "        fin.seek(-1024, 2)\n",
    "        end_content = fin.read()\n",
    "        end_content = end_content.decode(\"ascii\", 'ignore' )\n",
    "    start_flag = False\n",
    "    #%PDF\n",
    "    if start_content.count('%PDF') > 0:\n",
    "        start_flag = True\n",
    "    \n",
    "        \n",
    "    if end_content.count('%%EOF') and start_flag > 0:\n",
    "        return True\n",
    "    eof = bytes([0])\n",
    "    eof = eof.decode(\"ascii\")\n",
    "    if end_content.endswith(eof) and start_flag:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in pdfs:\n",
    "    if os.path.getsize(file) < 12 * 1024 or isFullPdf(file)!= True: #remove broken files\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = list()\n",
    "\n",
    "x = 0\n",
    "\n",
    "for i in pdfs:\n",
    "    try:\n",
    "        g.append(parser.from_file(i)) #read/parse all the files \n",
    "        g.append(i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annots = pd.read_excel('annots_neg.xlsx') #read in a .xlsx file containing one column of putative annotations (one lipid per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PS 40:6', 'PE 40:5', 'MGDG 34:1', 'PE 40:6', 'PS 38:4'}\n"
     ]
    }
   ],
   "source": [
    "annotations = set()\n",
    "\n",
    "for x in (annots['annotations_neg']): #annotation dataframe[name of the column]\n",
    "    for i in range(0,len(g),2):\n",
    "        temp_1 = re.findall(x, g[i]['content'])  \n",
    "        if len(temp_1) != 0:\n",
    "            annotations.add(temp_1[0]) #Find if annotation is mentioned in the literature, and if so, append\n",
    "            \n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
